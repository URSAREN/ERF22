\documentclass[11pt]{article}

\usepackage{sectsty}
\usepackage{graphicx}

% Margins
\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

% Images
\graphicspath{ {./images/} }

\title{RWTH Aachen University - LELY Solution Documentation}
\author{RWTH Team}
\date{\today}

\begin{document}
	\maketitle	
	
	\section{Abstract}
	
	Our solution to the LELY Challenge consists of a team of asymmetrical robots implemented in ROS. Robot A navigates and maps its environment with use of a 2D LIDAR system. Robot B recieves a map of the environment and location data from Robot A and then uses its 3 ultrasonic sensors to navigate. \newline
	
	This document provides an outline of the design of the systems and the thought process behind their development.	
	
	\section{Robot A}
	
	\subsection{Overview}
	Robot A is a LIDAR-capable platform. Due to the walls of the challenge being only 37cm tall, the mounting point of the LIDAR is on the bottom front of the chasis, providing a 200 degree field of view. The restricted point of view is overcome through the natural turning of the robot during navigation or through a simple and relatively quick rotation.
	
	\begin{figure}[h!]
		\centering
		\includegraphics[scale=0.1]{robot_a}
		\caption{The LIDAR sensor and 3D-printed mounting point attached to Robot A}
	\end{figure}
	
	\subsection{Sensors}
	A RPLIDAR A1M8-R6 LIDAR is mounted on the front of the robot. The LIDAR interfaces with the laptop directly over USB. \newline
	
	The A1M8-R6 was chosen due to its excellent support in the ROS ecosystem, allowing for the implementation of a straightfoward mapping stack. 
	
	\subsection{Hardware}
	A 3D-printed mount was created for easy placement and adjustment of the LIDAR.
	
	\begin{figure}[h!]
		\centering
		\includegraphics[scale=0.6]{lidar_mount}
		\caption{CAD rendering of LIDAR mount}
	\end{figure}
	
	\subsection{Software}
	The A1M8-R6 LIDAR comes with ROS packages which allow for SLAM mapping without odometry information up to 12 meters. An ideal navigation stack for Robot A would be to use the gmapping ROS package to generate a cost map, allowing for the robot to be steered via the ROS move\_base package. \newline
	
	However, due to technical difficulties with move\_base, Robot A implements a wall following and corner detection algorithem. Five equally-spaced lines in front of the robot are sampled via LIDAR allowing it to maintain a constant distance to walls and to count and detect corners. Diffrerentiating between corners with right turns and left turns allow the robot to locate itself in a predefined map with uncertain wall lengths.\newline
	
	\pagebreak

	\section{Robot B}
	
	\subsection{Overview}
	Robot B uses ultrasonic sensors mounted via aluminium frame to navigate its environment.
	
	\begin{figure}[h!]
		\centering
		\includegraphics[scale=0.1]{robot_b_full}
		\caption{Robot B with mounting frame, 3D-printed connectors, and ultrasonic sensors}
	\end{figure}
	
	\subsection{Sensors}
	Three HC-SR04 ultrasonic sensors are placed in an array around the robot. The sensors interface with the laptop via an Arduino Uno.
	
	\subsection{Hardware}
	An aluminium frame with 3D-printed connection points extends from the top mounting point to the bottom of the robot, allowing the sensors to attach to a low-enough point to read the walls of the maze.
	
	\pagebreak
	
	\begin{figure}[h!]
		\centering
		\includegraphics[scale=0.1]{ultrasonic_mount}
		\caption{Robot B with mounting frame, 3D-printed connectors, and ultrasonic sensors}
	\end{figure}
	
	\begin{figure}[h!]
		\centering
		\includegraphics[scale=0.5]{central_mount_empty}
		\caption{Central mount for connection points}
	\end{figure}

	\begin{figure}[h!]
		\centering
		\includegraphics[scale=0.5]{central_mount_conns}
		\caption{Central mount with connections for ultrasonic sensors}
	\end{figure}

	\pagebreak
	
	\subsection{Software}
	Robot B follows a similar algorithem to the ideal case of Robot A. After being located by Robot A and having recieved the LIDAR map, Robot B uses a wall following and corner counting algorithem.
	
\end{document}